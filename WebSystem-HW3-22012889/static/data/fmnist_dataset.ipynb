{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code loads the FashionMNIST dataset (both training and test sets), \n",
    " applies transformations (conversion to tensor and normalization), \n",
    " and display the first image of each class in both sets(train and test) using matplotlib in a 2x5 grid layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 전처리: 이미지를 텐서로 변환하고 정규화하기 위한 transform 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Adjusted for single-channel images\n",
    "])\n",
    "\n",
    "# 학습 데이터셋 다운로드\n",
    "trainset = datasets.FashionMNIST('', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 테스트 데이터셋 다운로드\n",
    "testset = datasets.FashionMNIST('', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Training set size: {len(trainset)} images\")\n",
    "print(f\"Test set size: {len(testset)} images\")\n",
    "\n",
    "# Plot graph for the trainset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "fig.suptitle(\"Sample Images from Fashion MNIST Classes\")\n",
    "\n",
    "# Define the class labels for Fashion MNIST\n",
    "class_labels = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "    'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "# Visualize the first image from each class in the trainset\n",
    "for i in range(10):\n",
    "    # 각 클래스의 첫 번째 이미지 찾기\n",
    "    first_idx = next(idx for idx, (_, label) in enumerate(trainset) if label == i)\n",
    "    image, label = trainset[first_idx]\n",
    "\n",
    "    # 이미지 시각화\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(image.squeeze(), cmap='gray')  # 이미지에서 배치 차원 제거\n",
    "    ax.set_title(f\"Train: {class_labels[label]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot graph for the testset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "fig.suptitle(\"Sample Images from Fashion MNIST Test Set\")\n",
    "\n",
    "# Visualize the first image from each class in the testset\n",
    "for i in range(10):\n",
    "    # 각 클래스의 첫 번째 이미지 찾기\n",
    "    first_idx = next(idx for idx, (_, label) in enumerate(testset) if label == i)\n",
    "    image, label = testset[first_idx]\n",
    "\n",
    "    # 이미지 시각화\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(image.squeeze(), cmap='gray')  # 이미지에서 배치 차원 제거\n",
    "    ax.set_title(f\"Test: {class_labels[label]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# Define a simple neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # 28x28 images flattened into a vector\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer with 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation for the first hidden layer\n",
    "        x = self.fc2(x)  # Output layer (logits)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the weights\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation\n",
    "Visualize predicted images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "images_for_visualization = []  # Store the images from the batch for visualization\n",
    "\n",
    "# No need to calculate gradients during evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "        total += labels.size(0)  # Total number of images\n",
    "        correct += (predicted == labels).sum().item()  # Correct predictions\n",
    "        predictions.extend(predicted.numpy())  # Store predictions\n",
    "        true_labels.extend(labels.numpy())  # Store true labels\n",
    "        images_for_visualization.extend(images.numpy())  # Store images for visualization\n",
    "\n",
    "accuracy = 100 * correct / total  # Calculate the accuracy percentage\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Visualization function for predicted images with true and predicted labels\n",
    "def visualize_predictions(images, true_labels, predictions, num=10):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(num):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')  # Display the image\n",
    "        # Display true and predicted labels under the image\n",
    "        plt.title(f'True: {class_labels[true_labels[i]]}\\nPred: {class_labels[predictions[i]]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions from the images stored for visualization\n",
    "visualize_predictions(images_for_visualization, true_labels, predictions, num=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load images from the FashionMNIST training set. \n",
    " 3 sample images for each class are save in separate folders (e.g., T-shirt_top, Trouser, etc.) \n",
    " inside the base directory ./Fmnist_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory to save the images\n",
    "save_dir = './Fmnist_images'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Define the class labels for Fashion MNIST, replacing slashes with underscores to avoid confusion\n",
    "class_labels = [\n",
    "    'T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "    'Shirt', 'Sneaker', 'Bag', 'Ankle_boot'\n",
    "]\n",
    "\n",
    "# Dictionary to keep track of saved images per class\n",
    "saved_counts = {class_name: 0 for class_name in class_labels}\n",
    "\n",
    "# Find and save images for each class\n",
    "for idx, (image_tensor, label) in enumerate(trainset):\n",
    "    class_name = class_labels[label]\n",
    "\n",
    "    # Check if we have saved 3 images for this class\n",
    "    if saved_counts[class_name] < 3:\n",
    "        # Create a folder for each class inside the save directory\n",
    "        class_dir = os.path.join(save_dir, class_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # De-normalize and convert to PIL Image\n",
    "        image_tensor = image_tensor * 0.5 + 0.5  # De-normalize to [0, 1] range\n",
    "        image_pil = transforms.ToPILImage()(image_tensor.squeeze(0))  # Remove channel dimension\n",
    "\n",
    "        # Save the image with a unique filename in the class folder\n",
    "        image_path = os.path.join(class_dir, f\"{class_name}_{saved_counts[class_name] + 1}.png\")\n",
    "        image_pil.save(image_path)\n",
    "        print(f\"Saved {image_path}\")\n",
    "\n",
    "        # Update the count for this class\n",
    "        saved_counts[class_name] += 1\n",
    "\n",
    "    # Stop if we have saved 3 images for each class\n",
    "    if all(count == 3 for count in saved_counts.values()):\n",
    "        break\n",
    "\n",
    "print(\"Images saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
